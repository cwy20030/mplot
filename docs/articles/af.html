<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Simplified adaptive fence â€¢ mplot</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/lumen/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">mplot</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Theory
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/background.html">Background and philosophy</a>
    </li>
    <li>
      <a href="../articles/vip.html">Variable inclusion plots</a>
    </li>
    <li>
      <a href="../articles/msp.html">Model stability plots</a>
    </li>
    <li>
      <a href="../articles/af.html">Adaptive fence</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Applications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/diabetes.html">Diabetes</a>
    </li>
    <li>
      <a href="../articles/birthweight.html">Birth weight</a>
    </li>
    <li>
      <a href="../articles/artificial.html">Artificial example</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tips
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/interactive.html">Interactive plots</a>
    </li>
    <li>
      <a href="../articles/timing.html">Timing</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/garthtarr/mplot">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/people.html">
    <span class="fa fa-info-circle fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Simplified adaptive fence</h1>
            
          </div>

    
    
<div class="contents">
<blockquote>
<p>Overview of the simplified adaptive fence procedure.</p>
</blockquote>
<p>The fence, first introduced by <span class="citation">Jiang et al. (2008)</span>, is built around the inequality <span class="math display">\[\hat{Q}(\alpha) - \hat{Q}(\alpha_{f}) \leq c,\]</span> where <span class="math inline">\(\hat Q\)</span> is an empirical measure of description loss, <span class="math inline">\(\alpha\)</span> is a candidate model and <span class="math inline">\(\alpha_{f}\)</span> is the baseline, <em>full</em> model. The procedure attempts to isolate a set of <em>correct models</em> that satisfy the inequality. A model <span class="math inline">\(\alpha^*\)</span>, is described as <em>within the fence</em> if <span class="math inline">\(\hat{Q}(\alpha^*) - \hat{Q}(\alpha_{f}) \leq c\)</span>. From the set of models within the fence, the one with minimum dimension is considered optimal. If there are multiple models within the fence at the minimum dimension, then the model with the smallest <span class="math inline">\(\hat{Q}(\alpha)\)</span> is selected. For a recent review of the fence and related methods, see <span class="citation">Jiang (2014)</span>.</p>
<p>The implementation we provide in the <strong>mplot</strong> package is inspired by the simplified adaptive fence proposed by <span class="citation">Jiang et al. (2009)</span>, which represents a significant advance over the original fence method proposed by <span class="citation">Jiang et al. (2008)</span>. The key difference is that the parameter <span class="math inline">\(c\)</span> is not fixed at a certain value, but is instead adaptively chosen. Simulation results have shown that the adaptive method improves the finite sample performance of the fence.</p>
<p>The adaptive fence procedure entails bootstrapping over a range of values of the parameter <span class="math inline">\(c\)</span>. For each value of <span class="math inline">\(c\)</span> a parametric bootstrap is performed under <span class="math inline">\(\alpha_f\)</span>. For each bootstrap sample we identify the smallest model inside the fence, <span class="math inline">\(\hat{\alpha}(c)\)</span>. <span class="citation">Jiang et al. (2009)</span> suggest that if there is more than one model, choose the one with the smallest <span class="math inline">\(\hat{Q}(\alpha)\)</span>. Define the empirical probability of selecting model <span class="math inline">\(\alpha\)</span> for a given value of <span class="math inline">\(c\)</span> as <span class="math inline">\(p^*(c,\alpha)=P^*\{\hat{\alpha}(c)=\alpha\}\)</span>. Hence, if <span class="math inline">\(B\)</span> bootstrap replications are performed, <span class="math inline">\(p^*(c,\alpha)\)</span> is the proportion of times that model <span class="math inline">\(\alpha\)</span> is selected. Finally, define an overall selection probability, <span class="math inline">\(p^*(c)=\max_{\alpha\in\mathcal{A}}p^*(c,\alpha)\)</span> and plot <span class="math inline">\(p^*(c)\)</span> against <span class="math inline">\(c\)</span> to find the first peak. The value of <span class="math inline">\(c\)</span> at the first peak, <span class="math inline">\(c^*\)</span>, is then used with the standard fence procedure on the original data.</p>
<p>Our implementation is provided through the <code><a href="../reference/af.html">af()</a></code> function and associated plot methods. An example with the artificial data set is generated using the following code.</p>
<div class="sourceCode"><pre class="sourceCode s"><code class="sourceCode gnuassembler">af.art = af(lm.art, B = <span class="dv">150</span>, n.c = <span class="dv">50</span>)
plot(af.art, interactive = FALSE, best.only = TRUE)</code></pre></div>
<p>The arguments indicate that we perform <span class="math inline">\(B = 150\)</span> bootstrap resamples, over a grid of <span class="math inline">\(50\)</span> values of the parameter <span class="math inline">\(c\)</span>. In this example, there is only one peak, and the choice of <span class="math inline">\(c^*=21.1\)</span> is clear.</p>
<div id="fig:plot-af">
<p><img src="images/artafboTF.png"></p>
</div>
<p><em>Result of a call to <code>plot(af.art, interactive = FALSE)</code> with additional arguments <code>best.only = TRUE</code> on the left and <code>best.only = FALSE</code> on the right. The more rapid decay after the <span class="math inline">\(x_8\)</span> model is typical of using <code>best.only = FALSE</code> where the troughs between candidate/dominant models are more pronounced.</em></p>
<p>One might expect that there should be a peak corresponding to the full model at <span class="math inline">\(c=0\)</span>, but this is avoided by the inclusion of at least one redundant variable. Any model that includes the redundant variable is known to not be a <em>true</em> model and hence is not included in the calculation of <span class="math inline">\(p^*(c)\)</span>. This issue was first identified and addressed by <span class="citation">Jiang et al. (2009)</span>.</p>
<p>There are a number of key differences between our implementation and the method proposed by <span class="citation">Jiang et al. (2009)</span>. Perhaps the most fundamental difference is in the philosophy underlying our implementation. Our approach is more closely aligned with the concept of model stability than with trying to pick a single <em>best</em> model. This can be seen through the plot methods we provide. Instead of simply using the plots to identify the first peak, we add a legend that highlights which models were the most frequently selected for each parameter value, that is, for each <span class="math inline">\(c\)</span> value we identify which model gave rise to the <span class="math inline">\(p^*(c)\)</span> value. In this way, researchers can ascertain if there are regions of stability for various models. In the example given above, there is no need to even define a <span class="math inline">\(c^*\)</span> value, it is obvious from the plot that there is only one viable candidate model, a regression of <span class="math inline">\(y\)</span> on <span class="math inline">\(x_8\)</span>.</p>
<p>Our approach considers not just the best model of a given model size, but also allows users to view a plot that takes into account the possibility that more than one model of a given model size is within the fence. The <code>best.only = FALSE</code> option when plotting the results of the adaptive fence is a modification of the adaptive fence procedure which considers all models of a particular size that are within the fence when calculating the <span class="math inline">\(p^*(c)\)</span> values. In particular, for each value of <span class="math inline">\(c\)</span> and for each bootstrap replication, if a candidate model is found inside the fence, then we look to see if there are any other models of the same size that are also within the fence. If no other models of the same size are inside the fence, then that model is allocated a weight of 1. If there are two models inside the fence, then the best model is allocated a weight of 1/2. If three models are inside the fence, the best model gets a weight of 1/3, and so on. After <span class="math inline">\(B\)</span> bootstrap replications, we aggregate the weights by summing over the various models. The <span class="math inline">\(p^*(c)\)</span> value is the maximum aggregated weight divided by the number of bootstrap replications. This correction penalises the probability associated with the best model if there were other models of the same size inside the fence. The rationale is that if a model has no redundant variables then it will be the only model of that size inside the fence over a range of values of <span class="math inline">\(c\)</span>. The result is more pronounced peaks which can help to determine the location of the correct peak and identify the optimal <span class="math inline">\(c^*\)</span> value or more clearly differentiate regions of model stability. This can be seen in the right hand panel of the figure above.</p>
<p>Another key difference is that our implementation is designed for linear and generalised linear models, rather than mixed models. As far as we are aware, this is the first time fence methods have been applied to such models. There is potential to add mixed model capabilities to future versions of the <strong>mplot</strong> package, but computational speed is a major hurdle that needs to be overcome. The current implementation is made computationally feasible through the use of the <strong>leaps</strong> and <strong>bestglm</strong> packages and the use of parallel processing <span class="citation">(Lumley &amp; Miller, 2009; McLeod &amp; Xu, 2014)</span>.</p>
<p>We have also provided an optional initial stepwise screening method that can help limit the range of <span class="math inline">\(c\)</span> values over which to perform the adaptive fence procedure. The initial stepwise procedure performs forward and backward stepwise model selection using both the AIC and BIC. From the four candidate models, we extract the size of smallest and largest models, <span class="math inline">\(k_L\)</span> and <span class="math inline">\(k_U\)</span> respectively. To obtain a sensible range of <span class="math inline">\(c\)</span> values we consider the set of models with dimension between <span class="math inline">\(k_L-2\)</span> and <span class="math inline">\(k_U+2\)</span>. Due to the inherent limitations of stepwise procedures, it can be useful to check <code>initial.stepwise = FALSE</code> with a small number of bootstrap replications over a sparse grid of <span class="math inline">\(c\)</span> values to ensure that the <code>initial.stepwise = TRUE</code> has produced a reasonable region.</p>
<div id="references" class="section level4 unnumbered">
<h4 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h4>
<div id="refs" class="references">
<div id="ref-Jiang:2014">
<p>Jiang, J. (2014). The fence methods. <em>Advances in Statistics</em>, 2014, 1â€“14. DOI:<a href="https://doi.org/10.1155/2014/830821">10.1155/2014/830821</a></p>
</div>
<div id="ref-Jiang:2009">
<p>Jiang, J., Nguyen, T., &amp; Rao, J. S. (2009). A simplified adaptive fence procedure. <em>Statistics &amp; Probability Letters</em>, 79(5), 625â€“629. DOI:<a href="https://doi.org/10.1016/j.spl.2008.10.014">10.1016/j.spl.2008.10.014</a></p>
</div>
<div id="ref-Jiang:2008">
<p>Jiang, J., Rao, J. S., Gu, Z., &amp; Nguyen, T. (2008). Fence methods for mixed model selection. <em>The Annals of Statistics</em>, 36(4), 1669â€“1692. DOI:<a href="https://doi.org/10.1214/07-AOS517">10.1214/07-AOS517</a></p>
</div>
<div id="ref-Lumley:2009">
<p>Lumley, T., &amp; Miller, A. (2009). <em>leaps: Regression subset selection</em>. <a href="http://CRAN.R-project.org/package=leaps" class="uri">http://CRAN.R-project.org/package=leaps</a></p>
</div>
<div id="ref-McLeod:2014">
<p>McLeod, A., &amp; Xu, C. (2014). <em>bestglm: Best subset glm</em>. <a href="http://CRAN.R-project.org/package=bestglm" class="uri">http://CRAN.R-project.org/package=bestglm</a></p>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Garth Tarr, Samuel Mueller, Alan H Welsh.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
