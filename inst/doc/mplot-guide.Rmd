---
title: "A brief introduction to mplot"
author: "Garth Tarr"
date: "`s Sys.Date()`"
output: html_document
---

<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{A brief introduction to mplot}
-->

# A brief introduction to mplot

The **mplot** package implements a range of model selection procedures and model stability plots designed to provide users with the information they need to make informed decisions about model selection issues in linear and mixed models.

There are two main componenets: model selection via the adaptive fence procedure (Jiang et. al., 2009) and model stability curves as described in MÃ¼ller and Welsh (2010).

## Adaptive fence

The adaptive fence procedure is ... super brief recap of theory here.

### Artificial example

The adaptive fence procedure is (currently; in future it will be wrapped into the higher level `fencer` function) implemented through the function `af` as follows:

```{r artificial.eg, results='asis', tidy=FALSE}
require(mplot,quietly=TRUE)
op = options(gvis.plot.tag = "chart")
n = 100
set.seed(11)
e = rnorm(n)
x0 = 1
x1 = rnorm(n)
x2 = rnorm(n)
x3 = x1^2
x4 = x2^2
x5 = x1*x2
y = x0 + x1 + x2 + e
dat = data.frame(y,x1,x2,x3,x4,x5)
af1 = af(y~., data=dat, n.cores=3)
```
```{r}
summary(af1)
```

```{r af1plot, results='asis', tidy=FALSE}
plot(af1)
```

In this example, we can see that the first (and only) peak in the plot of $p^*$ against $c$ occurs for the model of $y$ against $x_1$ and $x_2$.  The $c^*$ value is `r round(af1$c.star,1)`, and the model selected as a result of using that $c^*$ value is given in the summary output.  Note that the range of $c$ was predetermined by considering models selected using an initial application of forward and backward searches.

### Real world example

If there exists a *true* model, the adaptive fence tends to find it quite easily.  In practice, there is rarely such a well defined and readily identifiable data generating process and it is the role of the investigator to make a judgement call as to which model *best* describes the underlying process.  A nice feature of the adaptive fence procedure is its ability to guide the investigator and highlight plausible candidate models.

Consider the body fat example of CITATION HERE.  

```{r bdat.full.plot, results='asis', tidy=FALSE}
bfat.full = af(Bodyfat~.,data=bodyfat,n.cores=3, n.c=100,initial.stepwise=FALSE)
plot(bfat.full)
```

Note that if we consider the full range of possible values for the parameter $c$, by setting `initial.stepwise=FALSE`, it appears that there is one dominant variable, `abdo`, and hence naiively, one might chose a simple linear regression of `Bodyfat` on `abdo`.

Instead, one might like to incorporate some additional information to better inform our choice.  In particular, let us consider the number of variables that AIC and BIC forward and backward stepwise procedures and investigate only models of similar size.

```{r bfat.stepwise.plot, results='asis', tidy=FALSE}
bfat.stepwise = af(Bodyfat~.,data=bodyfat,n.cores=3, n.c=50,initial.stepwise=TRUE)
plot(bfat.stepwise)
```

Doing this, we focus attention on smaller $c$ values, i.e. larger model sizes.  We can see that the regression of `Bodyfat` on `weight` and `abdo` is chosen over a large range of c values.  However, it is also important to note that in this range, the pstar values are all quite low, suggesting that there is no one dominant model that *best* describes the data generating process.

```{r}
summary(bfat.stepwise)
```

### Mixed model example

Yet to be implemented.

## Model selection curves

Yet to be implemented.